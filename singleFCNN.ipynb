{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "singleFCNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNGSv5B13ls2qsEfojE+PV8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LokiAndere/After_MIARFID/blob/main/singleFCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4kFgqxh2kem",
        "outputId": "e11b6711-8276-4a90-bb62-b3f906d13f96"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88cz38Km5vW8"
      },
      "source": [
        "from keras.applications.resnet50 import preprocess_input\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import LearningRateScheduler as LRS\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.optimizers import SGD\n",
        "from keras.utils import to_categorical"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCe-ofUcd8lt"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy.stats import zscore\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler, Normalizer, Binarizer\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYwq6vEXzaqP"
      },
      "source": [
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jo7H0HEHzbE2"
      },
      "source": [
        "import keras.backend as BCKN\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, BatchNormalization, Dropout, Flatten, Dense\n",
        "from keras.layers import Dropout, Flatten, Dense, DepthwiseConv2D, GlobalAveragePooling2D\n",
        "from keras.layers import BatchNormalization as BN\n",
        "from keras.layers import ReLU, Softmax\n",
        "from keras.utils.vis_utils import plot_model"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "veEVrIWQzisk"
      },
      "source": [
        "def FCNN (shape, num_classes):\n",
        "  def CR (model, filters):\n",
        "    model = Conv2D(filters, 3) (model)\n",
        "    model = ReLU() (model)\n",
        "    return model\n",
        "\n",
        "  def CRCRMP (model, filters):\n",
        "    model = CR(model, filters)\n",
        "    model = CR(model, filters)\n",
        "    model = Conv2D(filters, 2, strides = 2) (model)\n",
        "    return model\n",
        "\n",
        "  def DR (model, filters):\n",
        "    model = Dense(filters) (model)\n",
        "    model = ReLU() (model)\n",
        "    return model\n",
        "\n",
        "  first = Input (shape)\n",
        "  model = CRCRMP (first, 16)\n",
        "  model = CRCRMP (model, 64)\n",
        "  model = Dropout (0.2) (model)\n",
        "  model = CR (model, 64)\n",
        "  model = CR (model, 128)\n",
        "  model = BN () (model)\n",
        "  model = Flatten () (model)\n",
        "  model = DR (model, 64)\n",
        "  model = Dropout (0.2) (model)\n",
        "  model = DR (model, 32)\n",
        "  model = DR (model, 32)\n",
        "  model = Dense (num_classes) (model)\n",
        "  last = Softmax () (model)\n",
        "  final = Model (first, last)\n",
        "  return final"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIYak3hOzvAV"
      },
      "source": [
        "shape = (100, 100, 1)\n",
        "num_classes = 2"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2JwobILMzyTI",
        "outputId": "e3def56e-eda5-477e-d3f8-166a5b58089e"
      },
      "source": [
        "BCKN.clear_session()\n",
        "model = FCNN(shape, num_classes)\n",
        "model.summary()\n",
        "#plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 100, 100, 1)]     0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 98, 98, 16)        160       \n",
            "_________________________________________________________________\n",
            "re_lu (ReLU)                 (None, 98, 98, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 96, 96, 16)        2320      \n",
            "_________________________________________________________________\n",
            "re_lu_1 (ReLU)               (None, 96, 96, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 48, 48, 16)        1040      \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 46, 46, 64)        9280      \n",
            "_________________________________________________________________\n",
            "re_lu_2 (ReLU)               (None, 46, 46, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 44, 44, 64)        36928     \n",
            "_________________________________________________________________\n",
            "re_lu_3 (ReLU)               (None, 44, 44, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 22, 22, 64)        16448     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 22, 22, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 20, 20, 64)        36928     \n",
            "_________________________________________________________________\n",
            "re_lu_4 (ReLU)               (None, 20, 20, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 18, 18, 128)       73856     \n",
            "_________________________________________________________________\n",
            "re_lu_5 (ReLU)               (None, 18, 18, 128)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 18, 18, 128)       512       \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 41472)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                2654272   \n",
            "_________________________________________________________________\n",
            "re_lu_6 (ReLU)               (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "re_lu_7 (ReLU)               (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "re_lu_8 (ReLU)               (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 2)                 66        \n",
            "_________________________________________________________________\n",
            "softmax (Softmax)            (None, 2)                 0         \n",
            "=================================================================\n",
            "Total params: 2,834,946\n",
            "Trainable params: 2,834,690\n",
            "Non-trainable params: 256\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOZJ3Uhc0J4q"
      },
      "source": [
        "def MobNet (shape, num_classes, alpha=1, ro=1, filter_one=32):\n",
        "\n",
        "  #alpha should be 1/4, 1/2, 3/4, 1\n",
        "  #basically between 0 and 1\n",
        "  #it is a reduce multiplyer of net arcitecture\n",
        "  #ro is reduce multiplyer of input image\n",
        "  #also between 0 and 1\n",
        "\n",
        "  #also additionally we included the number of filters to begin with\n",
        "  #instead of 32 we can put another minimum 16 and then we grow it like 2**n\n",
        "\n",
        "  #remember to reshape the image accordingly\n",
        "\n",
        "  #block that puts batch normalization and relu\n",
        "  #because we are tired of writing it each time\n",
        "  def BNR(model):\n",
        "    model = BN() (model)\n",
        "    model = ReLU() (model)\n",
        "    return model\n",
        "\n",
        "  #standart block\n",
        "  #you guessed it each convolution is proceeded with\n",
        "  #batch normalization and linear rectifier relu\n",
        "  def CBNR(model, filters, kernal, stride=1, padd='same'):\n",
        "    model = Conv2D (filters, kernal, strides=stride, padding=padd) (model)\n",
        "    model = BNR(model)\n",
        "    return model\n",
        "\n",
        "  #combo block\n",
        "  #deepwise convolution, in this way we save computational potency\n",
        "  #instead of one big convolutional block we brake it into two\n",
        "  #the first one is deepwise second is simple convolution\n",
        "  #less coeficients appear in this way\n",
        "  #too bad we did not perserve time to play with permute in all these exercises\n",
        "  #first convolution as easch convolution in this method\n",
        "  #is proceeded with batch normalization and relu\n",
        "  #and standart block inside\n",
        "  #we mean look at the name\n",
        "  #it is very self explainatory DCBNRCBNR\n",
        "  #for those to whom it is hard to read this\n",
        "  #we put a down underline separator\n",
        "  def DCBNR_CBNR(model, filters, stride=1, padd='same'):\n",
        "    model = DepthwiseConv2D(3, strides=stride, padding=padd) (model)\n",
        "    model = BNR(model)\n",
        "    model = CBNR(model, filters, 1)\n",
        "    return model\n",
        "\n",
        "  #we fill the arcitecture of light net\n",
        "  def fill(alpha=1, filters=32):\n",
        "    new_list = []\n",
        "    if filters<16:\n",
        "      filters = 32\n",
        "    if alpha<=0 or 1<alpha:\n",
        "        alpha=0.5\n",
        "    for n in range(6):\n",
        "        new_list.append(int(filters*alpha*2** n))\n",
        "    return new_list\n",
        "\n",
        "  if ro<=0 or 1<ro:\n",
        "    ro=0.5\n",
        "  tmp=list(int(s*ro) for s in shape[:-1])\n",
        "  tmp.append(shape[-1])\n",
        "  shape=tuple(tmp)\n",
        "\n",
        "  first = Input(shape)\n",
        "  #arch stends for arcitecture\n",
        "  arch = fill(alpha, filter_one)\n",
        "  #it seems like we can imagine a better automatization\n",
        "  #like one complex cycle\n",
        "  #because number of filters frows in a simple row a(n)=2^n\n",
        "  #but at this point we have not figured out it\n",
        "  #and from another point of view it is more readable\n",
        "  #and corelates strongly to paper table\n",
        "  model = CBNR(first, arch[0], 7, 2)\n",
        "  model = DCBNR_CBNR(model, arch[1])\n",
        "  model = DCBNR_CBNR(model, arch[2], 2)\n",
        "  model = DCBNR_CBNR(model, arch[2])\n",
        "  model = DCBNR_CBNR(model, arch[3], 2)\n",
        "  model = DCBNR_CBNR(model, arch[3])\n",
        "  model = DCBNR_CBNR(model, arch[4], 2)\n",
        "  for _ in range (5):\n",
        "    model = DCBNR_CBNR(model, arch[4])\n",
        "  model = DCBNR_CBNR(model, arch[5], 2)\n",
        "  #this one is strange. in the paper it is said to have stride step 2\n",
        "  #but the dimentions say it has to have stride = 1\n",
        "  model = DCBNR_CBNR(model, arch[5])\n",
        "\n",
        "  #tail\n",
        "  model = GlobalAveragePooling2D() (model)\n",
        "  model = Dense(num_classes) (model)\n",
        "  last = Softmax() (model)\n",
        "  final = Model(first, last)\n",
        "\n",
        "  return final"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yt2J_TD10XjG",
        "outputId": "f62ab685-e18a-446d-c644-fb1f3a2eb0fc"
      },
      "source": [
        "shape = (100, 100, 1)\n",
        "num_classes = 2\n",
        "alpha=0.25\n",
        "romashka=1\n",
        "first=16\n",
        "BCKN.clear_session()\n",
        "modelS = MobNet(shape, num_classes, alpha, romashka, first)\n",
        "modelS.summary()\n",
        "#plot_model(modelS, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 100, 100, 1)]     0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 50, 50, 4)         200       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 50, 50, 4)         16        \n",
            "_________________________________________________________________\n",
            "re_lu (ReLU)                 (None, 50, 50, 4)         0         \n",
            "_________________________________________________________________\n",
            "depthwise_conv2d (DepthwiseC (None, 50, 50, 4)         40        \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 50, 50, 4)         16        \n",
            "_________________________________________________________________\n",
            "re_lu_1 (ReLU)               (None, 50, 50, 4)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 50, 50, 8)         40        \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 50, 50, 8)         32        \n",
            "_________________________________________________________________\n",
            "re_lu_2 (ReLU)               (None, 50, 50, 8)         0         \n",
            "_________________________________________________________________\n",
            "depthwise_conv2d_1 (Depthwis (None, 25, 25, 8)         80        \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 25, 25, 8)         32        \n",
            "_________________________________________________________________\n",
            "re_lu_3 (ReLU)               (None, 25, 25, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 25, 25, 16)        144       \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 25, 25, 16)        64        \n",
            "_________________________________________________________________\n",
            "re_lu_4 (ReLU)               (None, 25, 25, 16)        0         \n",
            "_________________________________________________________________\n",
            "depthwise_conv2d_2 (Depthwis (None, 25, 25, 16)        160       \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 25, 25, 16)        64        \n",
            "_________________________________________________________________\n",
            "re_lu_5 (ReLU)               (None, 25, 25, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 25, 25, 16)        272       \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 25, 25, 16)        64        \n",
            "_________________________________________________________________\n",
            "re_lu_6 (ReLU)               (None, 25, 25, 16)        0         \n",
            "_________________________________________________________________\n",
            "depthwise_conv2d_3 (Depthwis (None, 13, 13, 16)        160       \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 13, 13, 16)        64        \n",
            "_________________________________________________________________\n",
            "re_lu_7 (ReLU)               (None, 13, 13, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 13, 13, 32)        544       \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 13, 13, 32)        128       \n",
            "_________________________________________________________________\n",
            "re_lu_8 (ReLU)               (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "depthwise_conv2d_4 (Depthwis (None, 13, 13, 32)        320       \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 13, 13, 32)        128       \n",
            "_________________________________________________________________\n",
            "re_lu_9 (ReLU)               (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 13, 13, 32)        1056      \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 13, 13, 32)        128       \n",
            "_________________________________________________________________\n",
            "re_lu_10 (ReLU)              (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "depthwise_conv2d_5 (Depthwis (None, 7, 7, 32)          320       \n",
            "_________________________________________________________________\n",
            "batch_normalization_11 (Batc (None, 7, 7, 32)          128       \n",
            "_________________________________________________________________\n",
            "re_lu_11 (ReLU)              (None, 7, 7, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 7, 7, 64)          2112      \n",
            "_________________________________________________________________\n",
            "batch_normalization_12 (Batc (None, 7, 7, 64)          256       \n",
            "_________________________________________________________________\n",
            "re_lu_12 (ReLU)              (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "depthwise_conv2d_6 (Depthwis (None, 7, 7, 64)          640       \n",
            "_________________________________________________________________\n",
            "batch_normalization_13 (Batc (None, 7, 7, 64)          256       \n",
            "_________________________________________________________________\n",
            "re_lu_13 (ReLU)              (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 7, 7, 64)          4160      \n",
            "_________________________________________________________________\n",
            "batch_normalization_14 (Batc (None, 7, 7, 64)          256       \n",
            "_________________________________________________________________\n",
            "re_lu_14 (ReLU)              (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "depthwise_conv2d_7 (Depthwis (None, 7, 7, 64)          640       \n",
            "_________________________________________________________________\n",
            "batch_normalization_15 (Batc (None, 7, 7, 64)          256       \n",
            "_________________________________________________________________\n",
            "re_lu_15 (ReLU)              (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 7, 7, 64)          4160      \n",
            "_________________________________________________________________\n",
            "batch_normalization_16 (Batc (None, 7, 7, 64)          256       \n",
            "_________________________________________________________________\n",
            "re_lu_16 (ReLU)              (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "depthwise_conv2d_8 (Depthwis (None, 7, 7, 64)          640       \n",
            "_________________________________________________________________\n",
            "batch_normalization_17 (Batc (None, 7, 7, 64)          256       \n",
            "_________________________________________________________________\n",
            "re_lu_17 (ReLU)              (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 7, 7, 64)          4160      \n",
            "_________________________________________________________________\n",
            "batch_normalization_18 (Batc (None, 7, 7, 64)          256       \n",
            "_________________________________________________________________\n",
            "re_lu_18 (ReLU)              (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "depthwise_conv2d_9 (Depthwis (None, 7, 7, 64)          640       \n",
            "_________________________________________________________________\n",
            "batch_normalization_19 (Batc (None, 7, 7, 64)          256       \n",
            "_________________________________________________________________\n",
            "re_lu_19 (ReLU)              (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 7, 7, 64)          4160      \n",
            "_________________________________________________________________\n",
            "batch_normalization_20 (Batc (None, 7, 7, 64)          256       \n",
            "_________________________________________________________________\n",
            "re_lu_20 (ReLU)              (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "depthwise_conv2d_10 (Depthwi (None, 7, 7, 64)          640       \n",
            "_________________________________________________________________\n",
            "batch_normalization_21 (Batc (None, 7, 7, 64)          256       \n",
            "_________________________________________________________________\n",
            "re_lu_21 (ReLU)              (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 7, 7, 64)          4160      \n",
            "_________________________________________________________________\n",
            "batch_normalization_22 (Batc (None, 7, 7, 64)          256       \n",
            "_________________________________________________________________\n",
            "re_lu_22 (ReLU)              (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "depthwise_conv2d_11 (Depthwi (None, 4, 4, 64)          640       \n",
            "_________________________________________________________________\n",
            "batch_normalization_23 (Batc (None, 4, 4, 64)          256       \n",
            "_________________________________________________________________\n",
            "re_lu_23 (ReLU)              (None, 4, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 4, 4, 128)         8320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_24 (Batc (None, 4, 4, 128)         512       \n",
            "_________________________________________________________________\n",
            "re_lu_24 (ReLU)              (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "depthwise_conv2d_12 (Depthwi (None, 4, 4, 128)         1280      \n",
            "_________________________________________________________________\n",
            "batch_normalization_25 (Batc (None, 4, 4, 128)         512       \n",
            "_________________________________________________________________\n",
            "re_lu_25 (ReLU)              (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 4, 4, 128)         16512     \n",
            "_________________________________________________________________\n",
            "batch_normalization_26 (Batc (None, 4, 4, 128)         512       \n",
            "_________________________________________________________________\n",
            "re_lu_26 (ReLU)              (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 2)                 258       \n",
            "_________________________________________________________________\n",
            "softmax (Softmax)            (None, 2)                 0         \n",
            "=================================================================\n",
            "Total params: 61,930\n",
            "Trainable params: 59,194\n",
            "Non-trainable params: 2,736\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMMQ5Hb9_Vfz"
      },
      "source": [
        "def normalize_zero_simple(x):\n",
        "  return (x.astype(float) - 128)/128\n",
        "\n",
        "def normalize_channel_vise(x):\n",
        "  x = x.astype('float32')\n",
        "  return (x - x.mean(axis = (0, 1, 2), keepdims = True)) / x.std(axis = (0, 1, 2), keepdims = True)\n",
        "\n",
        "def normalize_channel_vise_02(x):\n",
        "  x = x.astype('float32')\n",
        "  return zscore(x.reshape(-1, 3)).reshape(x.shape)\n",
        "\n",
        "def normalize_manually(x):\n",
        "  x = x.astype('float32')\n",
        "  x /= 255.0\n",
        "  return x\n",
        "\n",
        "def global_centering(x):\n",
        "  x = x.astype('float32') \n",
        "  x = x - x.mean()\n",
        "  return x\n",
        "\n",
        "def local_centering(x):\n",
        "  x = x.astype('float32')\n",
        "  means = x.mean(axis=(0,1), dtype='float64')\n",
        "  x =  x - means\n",
        "  return x\n",
        "\n",
        "def global_standardization(x):\n",
        "  x = x.astype('float32')\n",
        "  mean, std = x.mean(), x.std()\n",
        "  x = (x - mean) / std\n",
        "  return x\n",
        "\n",
        "def positive_global_standardization(x):\n",
        "  x = x.astype('float32')\n",
        "  mean, std = x.mean(), x.std()\n",
        "  x = (x - mean) / std\n",
        "  x = np.clip(x, -1.0, 1.0)\n",
        "  x = 0.5 * (x + 1.0)\n",
        "  return x\n",
        "\n",
        "def local_standardization(x):\n",
        "  x = x.astype('float32')\n",
        "  means = x.mean(axis=(0,1), dtype='float64')\n",
        "  stds = x.std(axis=(0,1), dtype='float64')\n",
        "  x = (x - means) / stds\n",
        "  return x"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Io7O1ZyP1xja"
      },
      "source": [
        "def draw_mpl(im, name = 'origin'):\n",
        "  name = name.title()\n",
        "  fig, ax = plt.subplots()\n",
        "  fig.canvas.set_window_title(name.upper())\n",
        "  ax.set_title(label=name, fontsize=16, color=\"black\")\n",
        "  ax.set_xlabel('x')\n",
        "  ax.set_ylabel('y')\n",
        "  ax.xaxis.set_ticks_position('top')\n",
        "  ax.xaxis.set_label_position:('top')\n",
        "  ax.xaxis.set_title_position:('top')\n",
        "  plt.imshow(im, cmap='gray')\n",
        "  plt.show()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVBJGequ0keA"
      },
      "source": [
        "DATA_PATH = '/content/drive/MyDrive/DefectDetection/100x100/'\n",
        "ARR_PATH = '/content/drive/MyDrive/DefectDetection/tog.npz'\n",
        "NARR_PATH = '/content/drive/MyDrive/DefectDetection/togn.npz'\n",
        "data = np.load(ARR_PATH)\n",
        "ndata = np.load(NARR_PATH)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "av3Sz2da0uPQ",
        "outputId": "775bc6f7-5969-43d5-f028-098e77dcafd5"
      },
      "source": [
        "X, y = data['x'], data['y']\n",
        "#X, y = ndata['xn'], ndata['yn']\n",
        "print(X.shape, y.shape)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(347, 100, 100) (347,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrKukxPC_75q"
      },
      "source": [
        "#X = preprocess_input(X)\n",
        "#scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "#scaler = Normalizer()\n",
        "scaler = StandardScaler()"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8pijOC68o98"
      },
      "source": [
        "for i in range (X.shape[0]):\n",
        "  #X[i] = global_standardization(X[i])\n",
        "  #X[i] = positive_global_standardization(X[i])\n",
        "  X[i] = local_standardization(X[i])\n",
        "  #X[i] = preprocessing.normalize(X[i]) #ok for 2 dimentions\n",
        "  #X[i] = scaler.fit_transform(X[i])\n",
        "  #X[i] = normalize_channel_vise_02(X[i])\n",
        "  pass"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6XtIHq_571j",
        "outputId": "14358a17-3e2a-4550-c57b-edf64d105dc6"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=1, stratify=y)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=1, stratify=y_train) # 0.25 x 0.8 = 0.2\n",
        "\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)\n",
        "print(y_val.shape)\n",
        "\n",
        "print(Counter(y_train))\n",
        "print(Counter(y_test))\n",
        "print(Counter(y_val))"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(207,)\n",
            "(70,)\n",
            "(70,)\n",
            "Counter({0: 129, 1: 78})\n",
            "Counter({0: 44, 1: 26})\n",
            "Counter({0: 43, 1: 27})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6BhoR2HTLhQ"
      },
      "source": [
        "X_train = X_train.reshape(207,100,100,1)\n",
        "X_test = X_test.reshape(70,100,100,1)\n",
        "X_val = X_test.reshape(70,100,100,1)\n",
        "X_train = X_train.astype('float32')\n",
        "X_test =X_test.astype('float32')\n",
        "X_val = X_val.astype('float32')\n",
        "\n",
        "#X_train /= 255.0\n",
        "#X_test /= 255.0\n",
        "#X_val /= 255.0\n",
        "y_train=to_categorical(y_train, num_classes)\n",
        "y_test=to_categorical(y_test, num_classes)\n",
        "y_val=to_categorical(y_val, num_classes)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "j4zZiH7v15sm",
        "outputId": "02fa5faf-aa0c-4e42-e5cb-a47a02ad6c24"
      },
      "source": [
        "i = 10\n",
        "draw_mpl(X[i], f\"sample {i}, label {y[i]}\")"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yz_vKc6GGn1"
      },
      "source": [
        "modelS.compile(optimizer = 'sgd', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TwkAMl7PHQmy",
        "outputId": "42e63556-c40d-415c-b9af-07ec415d39f9"
      },
      "source": [
        "#data_generator = ImageDataGenerator(samplewise_std_normalization=True, preprocessing_function=None)\n",
        "#train_generator = data_generator.flow_from_directory('/content/drive/MyDrive/DefectDetection/100x100/', target_size=(100,100), color_mode='grayscale', batch_size=23, class_mode='categorical')\n",
        "#test_generator = data_generator.flow_from_directory('/content/drive/MyDrive/DefectDetection/100x100/', target_size=(100,100), color_mode='grayscale', batch_size=23, class_mode='categorical')\n",
        "#validation_generator = data_generator.flow_from_directory('/content/drive/MyDrive/DefectDetection/100x100/', target_size=(100,100), color_mode='grayscale', batch_size=23, class_mode='categorical')"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 347 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/image_data_generator.py:356: UserWarning: This ImageDataGenerator specifies `samplewise_std_normalization`, which overrides setting of `samplewise_center`.\n",
            "  warnings.warn('This ImageDataGenerator specifies '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NUZ07ZWKMsg"
      },
      "source": [
        "modelS.fit_generator(\n",
        "    preprocess_function = preprocess_input,\n",
        "    train_generator,\n",
        "    steps_per_epoch=9,\n",
        "    validation_data=test_generator,\n",
        "    validation_steps=9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11ZjiDxvQ6VV"
      },
      "source": [
        "batch_size = 9\n",
        "epochs = 150"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqqFy18bPpZa"
      },
      "source": [
        "data_gen_with_aug = ImageDataGenerator(\n",
        "    rotation_range=35,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zqy0wYhARlfr"
      },
      "source": [
        "sgd=SGD(lr=0.1, decay=0.0, momentum=0.0)\n",
        "\n",
        "def scheduler(epoch):\n",
        "    if epoch < 50:\n",
        "        return 0.1\n",
        "    elif epoch < 100:\n",
        "        return 0.01\n",
        "    else:\n",
        "        return 0.001\n",
        "\n",
        "set_lr = LRS(scheduler)"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ms6FTY-aRKOJ"
      },
      "source": [
        "mcp_save1 = ModelCheckpoint ('/content/drive/MyDrive/DefectDetection/first.hdf5', save_best_only = True, monitor = 'val_acc', mode = 'auto')"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTs9Cec0Qv4j",
        "outputId": "8c480c81-b92e-47b0-e181-0cd11deb737d"
      },
      "source": [
        "history = modelS.fit_generator(data_gen_with_aug.flow(X_train, y_train,batch_size=batch_size),\n",
        "                            steps_per_epoch=len(X_train) / batch_size, \n",
        "                            epochs=epochs,\n",
        "                            validation_data=(X_test, y_test),\n",
        "                            callbacks=[set_lr, mcp_save1],\n",
        "                            verbose=1)\n",
        "\n",
        "score = modelS.evaluate(X_val, y_val, verbose=0)\n",
        "\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "23/23 [==============================] - 1s 18ms/step - loss: 0.4135 - accuracy: 0.7971 - val_loss: 0.3969 - val_accuracy: 0.8143\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 2/150\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.4098 - accuracy: 0.8406 - val_loss: 0.4069 - val_accuracy: 0.8286\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 3/150\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.3148 - accuracy: 0.8792 - val_loss: 0.3766 - val_accuracy: 0.8000\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 4/150\n",
            "23/23 [==============================] - 0s 15ms/step - loss: 0.3502 - accuracy: 0.8261 - val_loss: 1.6213 - val_accuracy: 0.6429\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 5/150\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.3306 - accuracy: 0.8599 - val_loss: 1.8618 - val_accuracy: 0.6000\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 6/150\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.2601 - accuracy: 0.8889 - val_loss: 6.0716 - val_accuracy: 0.4143\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 7/150\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.3642 - accuracy: 0.8599 - val_loss: 0.6123 - val_accuracy: 0.7000\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 8/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2722 - accuracy: 0.8937 - val_loss: 1.3996 - val_accuracy: 0.5857\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 9/150\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.2935 - accuracy: 0.8937 - val_loss: 0.8133 - val_accuracy: 0.7571\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 10/150\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.3211 - accuracy: 0.8599 - val_loss: 0.4219 - val_accuracy: 0.8286\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 11/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2452 - accuracy: 0.9082 - val_loss: 0.4375 - val_accuracy: 0.8000\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 12/150\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.2139 - accuracy: 0.9034 - val_loss: 0.7084 - val_accuracy: 0.7571\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 13/150\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.2138 - accuracy: 0.9324 - val_loss: 0.6767 - val_accuracy: 0.7857\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 14/150\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.3554 - accuracy: 0.8599 - val_loss: 0.7428 - val_accuracy: 0.7857\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 15/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2852 - accuracy: 0.8889 - val_loss: 0.4055 - val_accuracy: 0.8143\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 16/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2959 - accuracy: 0.8841 - val_loss: 0.5064 - val_accuracy: 0.8143\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 17/150\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.2866 - accuracy: 0.8792 - val_loss: 0.7056 - val_accuracy: 0.8000\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 18/150\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.3649 - accuracy: 0.8599 - val_loss: 0.3538 - val_accuracy: 0.9000\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 19/150\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.2887 - accuracy: 0.8986 - val_loss: 0.7002 - val_accuracy: 0.7571\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 20/150\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.2474 - accuracy: 0.8986 - val_loss: 0.6192 - val_accuracy: 0.7286\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 21/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.3286 - accuracy: 0.8647 - val_loss: 1.2993 - val_accuracy: 0.6143\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 22/150\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.3562 - accuracy: 0.8454 - val_loss: 0.6977 - val_accuracy: 0.7000\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 23/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2783 - accuracy: 0.8841 - val_loss: 1.8748 - val_accuracy: 0.6571\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 24/150\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.2916 - accuracy: 0.8792 - val_loss: 0.5259 - val_accuracy: 0.7571\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 25/150\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.3747 - accuracy: 0.8502 - val_loss: 0.5208 - val_accuracy: 0.7857\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 26/150\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.3574 - accuracy: 0.8744 - val_loss: 0.6691 - val_accuracy: 0.7571\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 27/150\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.2484 - accuracy: 0.8986 - val_loss: 0.7749 - val_accuracy: 0.7714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 28/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2927 - accuracy: 0.8599 - val_loss: 0.3839 - val_accuracy: 0.8143\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 29/150\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.3636 - accuracy: 0.8744 - val_loss: 0.3478 - val_accuracy: 0.8714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 30/150\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.2766 - accuracy: 0.8889 - val_loss: 0.3414 - val_accuracy: 0.8286\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 31/150\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.3130 - accuracy: 0.8696 - val_loss: 0.3516 - val_accuracy: 0.8429\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 32/150\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.3065 - accuracy: 0.8792 - val_loss: 0.3646 - val_accuracy: 0.8143\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 33/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.3364 - accuracy: 0.8357 - val_loss: 0.3615 - val_accuracy: 0.8714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 34/150\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.2336 - accuracy: 0.9179 - val_loss: 0.4015 - val_accuracy: 0.8571\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 35/150\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.3013 - accuracy: 0.8792 - val_loss: 0.5150 - val_accuracy: 0.7857\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 36/150\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.2634 - accuracy: 0.8696 - val_loss: 1.2069 - val_accuracy: 0.7571\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 37/150\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.3037 - accuracy: 0.8502 - val_loss: 0.4240 - val_accuracy: 0.8286\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 38/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2975 - accuracy: 0.8937 - val_loss: 0.4871 - val_accuracy: 0.8143\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 39/150\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.2407 - accuracy: 0.8986 - val_loss: 1.1113 - val_accuracy: 0.7714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 40/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2533 - accuracy: 0.9082 - val_loss: 0.6736 - val_accuracy: 0.7714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 41/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2634 - accuracy: 0.8696 - val_loss: 1.6264 - val_accuracy: 0.6571\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 42/150\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.3040 - accuracy: 0.8889 - val_loss: 0.8060 - val_accuracy: 0.7857\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 43/150\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.3161 - accuracy: 0.8696 - val_loss: 0.2907 - val_accuracy: 0.8429\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 44/150\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.2696 - accuracy: 0.8889 - val_loss: 0.3053 - val_accuracy: 0.8429\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 45/150\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.2505 - accuracy: 0.8986 - val_loss: 0.5457 - val_accuracy: 0.7714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 46/150\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.2965 - accuracy: 0.8599 - val_loss: 0.4550 - val_accuracy: 0.7714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 47/150\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.3996 - accuracy: 0.8357 - val_loss: 0.4599 - val_accuracy: 0.7857\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 48/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2903 - accuracy: 0.8744 - val_loss: 0.3334 - val_accuracy: 0.8714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 49/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2492 - accuracy: 0.8841 - val_loss: 0.3303 - val_accuracy: 0.8429\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 50/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.1631 - accuracy: 0.9517 - val_loss: 0.6270 - val_accuracy: 0.8000\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 51/150\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.2713 - accuracy: 0.9130 - val_loss: 0.4848 - val_accuracy: 0.7857\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 52/150\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.2326 - accuracy: 0.8937 - val_loss: 0.3914 - val_accuracy: 0.8429\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 53/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2697 - accuracy: 0.9130 - val_loss: 0.3415 - val_accuracy: 0.8571\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 54/150\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.2275 - accuracy: 0.9275 - val_loss: 0.2860 - val_accuracy: 0.8857\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 55/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2742 - accuracy: 0.8937 - val_loss: 0.3179 - val_accuracy: 0.8571\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 56/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2657 - accuracy: 0.8792 - val_loss: 0.3492 - val_accuracy: 0.8429\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 57/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2531 - accuracy: 0.9082 - val_loss: 0.3333 - val_accuracy: 0.8571\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 58/150\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.2841 - accuracy: 0.8841 - val_loss: 0.3231 - val_accuracy: 0.8571\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 59/150\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.2470 - accuracy: 0.8841 - val_loss: 0.3073 - val_accuracy: 0.8571\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 60/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2104 - accuracy: 0.9034 - val_loss: 0.3053 - val_accuracy: 0.8429\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 61/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2080 - accuracy: 0.9034 - val_loss: 0.3044 - val_accuracy: 0.8857\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 62/150\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.1594 - accuracy: 0.9517 - val_loss: 0.3129 - val_accuracy: 0.8714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 63/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2128 - accuracy: 0.9082 - val_loss: 0.3071 - val_accuracy: 0.8429\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 64/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.1682 - accuracy: 0.9324 - val_loss: 0.3168 - val_accuracy: 0.8571\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 65/150\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.2199 - accuracy: 0.9130 - val_loss: 0.3055 - val_accuracy: 0.8571\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 66/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2218 - accuracy: 0.8986 - val_loss: 0.2837 - val_accuracy: 0.8571\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 67/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2144 - accuracy: 0.9227 - val_loss: 0.3030 - val_accuracy: 0.8714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 68/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2168 - accuracy: 0.9324 - val_loss: 0.3237 - val_accuracy: 0.8714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 69/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2636 - accuracy: 0.9034 - val_loss: 0.2939 - val_accuracy: 0.8714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 70/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.1890 - accuracy: 0.9179 - val_loss: 0.2996 - val_accuracy: 0.8571\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 71/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.1711 - accuracy: 0.9469 - val_loss: 0.2981 - val_accuracy: 0.8571\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 72/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2178 - accuracy: 0.9130 - val_loss: 0.2938 - val_accuracy: 0.8714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 73/150\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.1935 - accuracy: 0.9275 - val_loss: 0.2932 - val_accuracy: 0.8571\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 74/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.1972 - accuracy: 0.9179 - val_loss: 0.2927 - val_accuracy: 0.8714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 75/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2692 - accuracy: 0.8841 - val_loss: 0.2905 - val_accuracy: 0.8714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 76/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2388 - accuracy: 0.9082 - val_loss: 0.3008 - val_accuracy: 0.8571\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 77/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.1891 - accuracy: 0.9372 - val_loss: 0.3006 - val_accuracy: 0.8857\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 78/150\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.2009 - accuracy: 0.9227 - val_loss: 0.3025 - val_accuracy: 0.8714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 79/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2015 - accuracy: 0.9275 - val_loss: 0.3029 - val_accuracy: 0.8714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 80/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.1774 - accuracy: 0.9179 - val_loss: 0.2851 - val_accuracy: 0.8571\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 81/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2417 - accuracy: 0.9082 - val_loss: 0.2789 - val_accuracy: 0.8714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 82/150\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.2032 - accuracy: 0.9324 - val_loss: 0.2695 - val_accuracy: 0.8857\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 83/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2206 - accuracy: 0.9179 - val_loss: 0.2647 - val_accuracy: 0.9000\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 84/150\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.1904 - accuracy: 0.9324 - val_loss: 0.2964 - val_accuracy: 0.8857\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 85/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.1837 - accuracy: 0.9082 - val_loss: 0.3083 - val_accuracy: 0.8857\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 86/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2209 - accuracy: 0.9130 - val_loss: 0.3092 - val_accuracy: 0.8714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 87/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2284 - accuracy: 0.8889 - val_loss: 0.3011 - val_accuracy: 0.8857\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 88/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.1862 - accuracy: 0.9227 - val_loss: 0.2806 - val_accuracy: 0.8714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 89/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2004 - accuracy: 0.8986 - val_loss: 0.2656 - val_accuracy: 0.8571\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 90/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.1806 - accuracy: 0.9372 - val_loss: 0.2613 - val_accuracy: 0.8714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 91/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2130 - accuracy: 0.9082 - val_loss: 0.2892 - val_accuracy: 0.8714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 92/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2263 - accuracy: 0.8889 - val_loss: 0.3060 - val_accuracy: 0.8714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 93/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.1519 - accuracy: 0.9517 - val_loss: 0.2923 - val_accuracy: 0.8571\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 94/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2548 - accuracy: 0.9082 - val_loss: 0.2842 - val_accuracy: 0.8714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 95/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.1936 - accuracy: 0.9275 - val_loss: 0.2865 - val_accuracy: 0.8571\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 96/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.1780 - accuracy: 0.9420 - val_loss: 0.3090 - val_accuracy: 0.8571\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 97/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.1500 - accuracy: 0.9517 - val_loss: 0.3028 - val_accuracy: 0.8429\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 98/150\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.2606 - accuracy: 0.8937 - val_loss: 0.2865 - val_accuracy: 0.8571\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 99/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2068 - accuracy: 0.9179 - val_loss: 0.2892 - val_accuracy: 0.8714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 100/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.1499 - accuracy: 0.9372 - val_loss: 0.2976 - val_accuracy: 0.8571\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 101/150\n",
            "23/23 [==============================] - 0s 19ms/step - loss: 0.1749 - accuracy: 0.9179 - val_loss: 0.2993 - val_accuracy: 0.8571\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 102/150\n",
            "23/23 [==============================] - 0s 19ms/step - loss: 0.2175 - accuracy: 0.9179 - val_loss: 0.2916 - val_accuracy: 0.8714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 103/150\n",
            "23/23 [==============================] - 0s 19ms/step - loss: 0.1729 - accuracy: 0.9469 - val_loss: 0.2903 - val_accuracy: 0.8714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 104/150\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.2550 - accuracy: 0.8841 - val_loss: 0.2923 - val_accuracy: 0.8714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 105/150\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.2677 - accuracy: 0.8841 - val_loss: 0.2908 - val_accuracy: 0.8714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 106/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2062 - accuracy: 0.9227 - val_loss: 0.2951 - val_accuracy: 0.8714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 107/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.1389 - accuracy: 0.9469 - val_loss: 0.2922 - val_accuracy: 0.8714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 108/150\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.2523 - accuracy: 0.8841 - val_loss: 0.2918 - val_accuracy: 0.8714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 109/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.1383 - accuracy: 0.9372 - val_loss: 0.2891 - val_accuracy: 0.8714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 110/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2233 - accuracy: 0.9179 - val_loss: 0.2905 - val_accuracy: 0.8714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 111/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2250 - accuracy: 0.9130 - val_loss: 0.2917 - val_accuracy: 0.8714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 112/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.1621 - accuracy: 0.9227 - val_loss: 0.2897 - val_accuracy: 0.8571\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 113/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2001 - accuracy: 0.9324 - val_loss: 0.2865 - val_accuracy: 0.8714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 114/150\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.2409 - accuracy: 0.9130 - val_loss: 0.2884 - val_accuracy: 0.8714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 115/150\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.1194 - accuracy: 0.9372 - val_loss: 0.2891 - val_accuracy: 0.8857\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 116/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2313 - accuracy: 0.8937 - val_loss: 0.2900 - val_accuracy: 0.8857\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 117/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.1883 - accuracy: 0.9227 - val_loss: 0.2898 - val_accuracy: 0.8857\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 118/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.1668 - accuracy: 0.9420 - val_loss: 0.2891 - val_accuracy: 0.8857\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 119/150\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.3331 - accuracy: 0.8647 - val_loss: 0.2875 - val_accuracy: 0.8857\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 120/150\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.1775 - accuracy: 0.9372 - val_loss: 0.2893 - val_accuracy: 0.8571\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 121/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2562 - accuracy: 0.8937 - val_loss: 0.2914 - val_accuracy: 0.8857\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 122/150\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.1609 - accuracy: 0.9420 - val_loss: 0.2906 - val_accuracy: 0.8714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 123/150\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.2159 - accuracy: 0.8986 - val_loss: 0.2895 - val_accuracy: 0.8714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 124/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2153 - accuracy: 0.9227 - val_loss: 0.2912 - val_accuracy: 0.8714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 125/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.1285 - accuracy: 0.9662 - val_loss: 0.2891 - val_accuracy: 0.8857\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 126/150\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.2247 - accuracy: 0.9082 - val_loss: 0.2883 - val_accuracy: 0.8857\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 127/150\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.1560 - accuracy: 0.9469 - val_loss: 0.2906 - val_accuracy: 0.8714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 128/150\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.2575 - accuracy: 0.9130 - val_loss: 0.2862 - val_accuracy: 0.8714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 129/150\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.1642 - accuracy: 0.9275 - val_loss: 0.2883 - val_accuracy: 0.8714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 130/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2447 - accuracy: 0.9275 - val_loss: 0.2934 - val_accuracy: 0.8714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 131/150\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.2287 - accuracy: 0.8937 - val_loss: 0.2931 - val_accuracy: 0.8714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 132/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.1891 - accuracy: 0.9517 - val_loss: 0.2923 - val_accuracy: 0.8571\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 133/150\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.1613 - accuracy: 0.9227 - val_loss: 0.2951 - val_accuracy: 0.8571\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 134/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2533 - accuracy: 0.8792 - val_loss: 0.2973 - val_accuracy: 0.8429\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 135/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2032 - accuracy: 0.9179 - val_loss: 0.2959 - val_accuracy: 0.8571\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 136/150\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.1655 - accuracy: 0.9275 - val_loss: 0.2935 - val_accuracy: 0.8571\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 137/150\n",
            "23/23 [==============================] - 0s 16ms/step - loss: 0.2249 - accuracy: 0.9130 - val_loss: 0.2934 - val_accuracy: 0.8429\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 138/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2203 - accuracy: 0.9082 - val_loss: 0.2960 - val_accuracy: 0.8571\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 139/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.1456 - accuracy: 0.9517 - val_loss: 0.2929 - val_accuracy: 0.8571\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 140/150\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.1554 - accuracy: 0.9275 - val_loss: 0.2910 - val_accuracy: 0.8571\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 141/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2353 - accuracy: 0.8841 - val_loss: 0.2882 - val_accuracy: 0.8714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 142/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2314 - accuracy: 0.9082 - val_loss: 0.2879 - val_accuracy: 0.8714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 143/150\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.1697 - accuracy: 0.9324 - val_loss: 0.2881 - val_accuracy: 0.8714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 144/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.1732 - accuracy: 0.9275 - val_loss: 0.2897 - val_accuracy: 0.8714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 145/150\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.2011 - accuracy: 0.9227 - val_loss: 0.2905 - val_accuracy: 0.8571\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 146/150\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.1535 - accuracy: 0.9372 - val_loss: 0.2895 - val_accuracy: 0.8571\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 147/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2703 - accuracy: 0.8841 - val_loss: 0.2899 - val_accuracy: 0.8714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 148/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.1484 - accuracy: 0.9324 - val_loss: 0.2874 - val_accuracy: 0.8714\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 149/150\n",
            "23/23 [==============================] - 0s 17ms/step - loss: 0.2318 - accuracy: 0.9179 - val_loss: 0.2880 - val_accuracy: 0.8571\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 150/150\n",
            "23/23 [==============================] - 0s 18ms/step - loss: 0.2135 - accuracy: 0.9082 - val_loss: 0.2914 - val_accuracy: 0.8571\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Test loss: 2.7654659748077393\n",
            "Test accuracy: 0.5285714268684387\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        },
        "id": "cVGWPuP-oXg2",
        "outputId": "eaff3709-2d0c-4eca-ed1c-d4c338d16eb5"
      },
      "source": [
        "history = modelS.fit((X_train, y_train),\n",
        "                            steps_per_epoch=23, \n",
        "                            epochs=150,\n",
        "                            validation_data=(X_test, y_test),\n",
        "                            verbose=1)\n",
        "\n",
        "score = modelS.evaluate(X_val, y_val, verbose=0)\n",
        "\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-79-ad900cee77e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m                             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                             \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                             verbose=1)\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodelS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2939\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[0;32m-> 2941\u001b[0;31m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3356\u001b[0m               call_context_key in self._function_cache.missed):\n\u001b[1;32m   3357\u001b[0m             return self._define_function_with_shape_relaxation(\n\u001b[0;32m-> 3358\u001b[0;31m                 args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001b[0m\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_define_function_with_shape_relaxation\u001b[0;34m(self, args, kwargs, flat_args, filtered_flat_args, cache_key_context)\u001b[0m\n\u001b[1;32m   3278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3279\u001b[0m     graph_function = self._create_graph_function(\n\u001b[0;32m-> 3280\u001b[0;31m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n\u001b[0m\u001b[1;32m   3281\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg_relaxed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrank_only_cache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\n        outputs = model.train_step(data)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:754 train_step\n        y_pred = self(x, training=True)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/input_spec.py:207 assert_input_compatibility\n        ' input tensors. Inputs received: ' + str(inputs))\n\n    ValueError: Layer model expects 1 input(s), but it received 2 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(9, 100, 100, 1) dtype=float32>, <tf.Tensor 'IteratorGetNext:1' shape=(9, 2) dtype=float32>]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "id": "-4TvoBbYsx6h",
        "outputId": "c74c2086-4459-48fd-f54b-38a70f7191b2"
      },
      "source": [
        "modelS.fit(x=X, y=y)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-80-6fd31f7b4949>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodelS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2939\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[0;32m-> 2941\u001b[0;31m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3356\u001b[0m               call_context_key in self._function_cache.missed):\n\u001b[1;32m   3357\u001b[0m             return self._define_function_with_shape_relaxation(\n\u001b[0;32m-> 3358\u001b[0;31m                 args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001b[0m\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_define_function_with_shape_relaxation\u001b[0;34m(self, args, kwargs, flat_args, filtered_flat_args, cache_key_context)\u001b[0m\n\u001b[1;32m   3278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3279\u001b[0m     graph_function = self._create_graph_function(\n\u001b[0;32m-> 3280\u001b[0;31m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n\u001b[0m\u001b[1;32m   3281\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg_relaxed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrank_only_cache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\n        outputs = model.train_step(data)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:756 train_step\n        y, y_pred, sample_weight, regularization_losses=self.losses)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/compile_utils.py:203 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/losses.py:152 __call__\n        losses = call_fn(y_true, y_pred)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/losses.py:256 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/losses.py:1537 categorical_crossentropy\n        return K.categorical_crossentropy(y_true, y_pred, from_logits=from_logits)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/backend.py:4833 categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/tensor_shape.py:1134 assert_is_compatible_with\n        raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\n\n    ValueError: Shapes (None, 1) and (None, 2) are incompatible\n"
          ]
        }
      ]
    }
  ]
}